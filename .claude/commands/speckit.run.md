---
description: Execute tasks from tasks.md with parallel subagent spawning, per-task verification, and lesson capture
model: opus
handoffs:
  - label: Run Full Test Suite
    agent: sc:test
    prompt: Run comprehensive tests for the implementation
  - label: Verify Feature
    agent: sc:verify
    prompt: Verify feature works end-to-end
---

## User Input
```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

**IMPORTANT**: Look for `FEATURE_DIR:` in the input above. If provided, use it directly instead of running the shell script.

## Outline

1. **Resolve feature context** (CRITICAL for subagent continuity):

   **Option A - FEATURE_DIR provided in input above**:
   - If you see `FEATURE_DIR: /path/to/specs/NNN-feature-name` in the input, use it directly
   - Set paths:
     - `TASKS` = `{FEATURE_DIR}/tasks.md`
     - `IMPL_PLAN` = `{FEATURE_DIR}/plan.md`
     - `FEATURE_SPEC` = `{FEATURE_DIR}/spec.md`
   - Skip the shell script entirely

   **Option B - No FEATURE_DIR provided (fallback)**:
   - Run `.specify/scripts/bash/check-prerequisites.sh --json --require-tasks --include-tasks` from repo root
   - Parse: `FEATURE_DIR`, `TASKS`, `IMPL_PLAN`, `FEATURE_SPEC`
   - If tasks.md missing, abort and instruct user to run `/speckit.tasks` first
   - For single quotes in args, use escape syntax: e.g `'I'\''m Groot'`

2. **Check checklists status** (if FEATURE_DIR/checklists/ exists):
   - Scan all checklist files in the checklists/ directory
   - For each checklist, count completed vs incomplete items
   - Create status table:
```
     | Checklist   | Total | Done | Incomplete | Status |
     |-------------|-------|------|------------|--------|
     | ux.md       | 12    | 12   | 0          | âœ“ PASS |
     | security.md | 6     | 4    | 2          | âœ— FAIL |
```
   - **If any incomplete**: STOP and ask user to proceed or halt
   - **If all complete**: Proceed automatically

3. **Load implementation context**:
   - **REQUIRED**: tasks.md, plan.md
   - **IF EXISTS**: data-model.md, contracts/, research.md, quickstart.md
   - **REQUIRED**: .specify/memory/constitution.md (project rules)

4. **Project setup verification** (from plan.md tech stack):
   - Create/verify .gitignore, .dockerignore, .eslintignore etc. based on detected tech
   - Append missing critical patterns to existing ignore files

5. **Parse tasks.md structure** (CRITICAL - read carefully):

   **A. Extract phases with dependencies:**
   ```
   For each "## Phase N:" header:
     - Extract phase number and name
     - Extract dependency comment: <!-- depends: X -->
     - Map dependencies: "foundation" = Phase 2, "USx" = User Story X
   ```

   **B. Extract execution groups:**
   ```
   GROUP EXTRACTION RULES (in order of precedence):

   1. [USx] label â†’ Group by User Story
      - All tasks with [US1] = one group named "US1"
      - All tasks with [US2] = one group named "US2"
      - etc.

   2. [G:name] label â†’ Explicit group
      - All tasks with [G:types] = one group named "types"
      - All tasks with [G:database] = one group named "database"
      - etc.

   3. No label â†’ Implicit phase group
      - All unlabeled tasks in a phase = one group named "phase-N"
   ```

   **C. Build execution map:**
   ```
   EXECUTION_MAP = {
     "phase-1": { groups: ["setup"], depends: [] },
     "phase-2": { groups: ["foundation"], depends: ["phase-1"] },
     "phase-3": { groups: ["US1"], depends: ["phase-2"] },
     "phase-4": { groups: ["US2"], depends: ["phase-2"] },
     "phase-5": { groups: ["US3"], depends: ["US2"] },
     "phase-6": { groups: ["polish"], depends: ["US1", "US2"] }
   }
   ```

6. **Check completion status and determine resume point** (CRITICAL for resumption):

   **A. Scan tasks.md for completion markers:**
   ```
   For each task line matching pattern: - [x] or - [ ]
     - [x] = completed
     - [ ] = incomplete
     - [x] with âœ“ (verified) = verified complete
     - [ ] with âŒ (error: ...) = failed, needs retry
   ```

   **B. Calculate completion per group:**
   ```
   For each group (G:types, US1, US2, etc.):
     - Count total tasks in group
     - Count completed tasks ([x])
     - Calculate percentage: completed/total * 100
     - Status: COMPLETE (100%), PARTIAL (1-99%), NOT_STARTED (0%)
   ```

   **C. Display resume status table:**
   ```
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    TASK COMPLETION STATUS
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

   | Wave | Group      | Total | Done | Status      |
   |------|------------|-------|------|-------------|
   | 1    | G:types    | 10    | 10   | âœ… COMPLETE  |
   | 2    | G:metadata | 9     | 9    | âœ… COMPLETE  |
   | 3    | US1        | 11    | 11   | âœ… COMPLETE  |
   | 3    | US2        | 4     | 2    | ğŸ”„ PARTIAL   |
   | 4    | US3        | 5     | 0    | â³ PENDING   |
   | 4    | US4        | 3     | 0    | â³ PENDING   |
   | 4    | US5        | 2     | 0    | â³ PENDING   |
   | 5    | G:polish   | 6     | 0    | â³ PENDING   |

   RESUME POINT: Wave 3 (US2 incomplete - 2/4 tasks done)

   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ```

   **D. Determine resume strategy:**
   ```
   IF all groups COMPLETE:
     â†’ Display "All tasks complete!" and skip to verification summary
     â†’ Offer to run final verification: /sc:test --comprehensive

   IF some groups PARTIAL or NOT_STARTED:
     â†’ Find first wave with incomplete groups
     â†’ For PARTIAL groups: re-run entire group (subagent will skip completed tasks internally)
     â†’ For NOT_STARTED groups in same wave: run in parallel with PARTIAL
     â†’ Resume from that wave

   IF --force-restart flag provided:
     â†’ Ignore completion status, re-run all waves from beginning
   ```

   **E. Handle partial groups:**
   ```
   When a group is PARTIAL (some tasks [x], some [ ]):
     - Include ONLY incomplete tasks in subagent prompt
     - Tell subagent which tasks are already done (for context)
     - Subagent implements remaining tasks only

   Example subagent prompt for partial group:
     "Execute Group: US2 (RESUMING)

      ## Already Completed (DO NOT re-implement)
      - [x] T031: Verify PhotographyParameterEditor uses PARAMETER_CATEGORIES
      - [x] T032: Update PARAMETER_DESCRIPTIONS in prompt-enhancement.ts

      ## Remaining Tasks (implement these)
      - [ ] T033: Update allParams array in buildStructuredSystemPrompt()
      - [ ] T034: Update mergeParameters() to include new params

      ..."
   ```

7. **Handle flags**:
   - `--dry-run`: Display execution map with completion status and exit
   - `--phase N`: Execute only phase N
   - `--retry GROUP`: Retry specific group (e.g., `--retry US2`)
   - `--skip-tests`: Skip per-group verification (not recommended)
   - `--force-restart`: Ignore completion status, re-run ALL waves from beginning
   - `--from-wave N`: Start execution from wave N (skip earlier waves even if incomplete)
   - `--skip-review`: Skip code review step (faster but may leave DRY violations)
   - `--review-only`: Run code review but don't apply fixes (report mode)

8. **Execute by groups** (THE CORE ALGORITHM):

   ```
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘  CRITICAL EXECUTION RULE                                        â•‘
   â•‘                                                                  â•‘
   â•‘  ONE SUBAGENT PER GROUP                                         â•‘
   â•‘                                                                  â•‘
   â•‘  â€¢ A group is: all tasks with same [USx] or [G:name]           â•‘
   â•‘  â€¢ One subagent receives ALL tasks in its group                 â•‘
   â•‘  â€¢ The subagent implements the COMPLETE group                   â•‘
   â•‘  â€¢ [P] markers are documentation only - do NOT spawn extra     â•‘
   â•‘    subagents for [P] tasks                                      â•‘
   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ```

   **A. Determine execution waves:**

   Groups whose dependencies are satisfied can run in PARALLEL.

   ```
   Wave 1: [Setup] - no dependencies
   Wave 2: [Foundation] - depends on Setup
   Wave 3: [US1], [US2], [US4] - all depend only on Foundation (PARALLEL!)
   Wave 4: [US3] - depends on US2
   Wave 5: [Polish] - depends on US1, US2
   ```

   **B. For each wave, spawn subagents:**

   **Single group in wave** â†’ spawn 1 subagent:
   ```
   Task tool:
     subagent_type: [auto-detect from task content - see section C]
     model: [select based on subagent_type - see MODEL SELECTION below]
     prompt: |
       Execute Group: {GROUP_NAME}

       ## Tasks (implement ALL in order, [P] = no internal dependencies)
       {FULL_TASK_LIST_WITH_IDS_FILES_CRITERIA}

       ## Goal
       {PHASE_GOAL_OR_STORY_DESCRIPTION}

       ## Context
       - Constitution: .specify/memory/constitution.md
       - Plan: {IMPL_PLAN}
       - Spec: {FEATURE_SPEC}

       ## Instructions
       1. Read constitution first (project rules)
       2. Implement ALL tasks in this group
       3. Tasks marked [P] have no internal dependencies - do in any efficient order
       4. Tasks without [P] should be done in listed order
       5. For API endpoints: create Bruno request files in api-collections/
       6. After ALL tasks complete, run SELF-VERIFICATION (MANDATORY)
       7. Report: all files changed, test results, any issues

       ## [IF FRONTEND AGENT] Visual Verification with Playwright
       You MUST visually verify your UI work using Playwright MCP:
       âš ï¸ FIRST run: .claude/scripts/get-dev-ports.sh to get current URLs
       1. Ensure dev server is running (or start with: bun run dev)
       2. browser_navigate to the discovered web URL (the page where your component lives)
       3. browser_snapshot to verify it renders correctly
       4. browser_console_messages to check for errors (should be none)
       5. browser_click on buttons/links to test they work
       6. browser_take_screenshot to capture evidence
       DO NOT report done without visual verification!

       ## SELF-VERIFICATION CHECKLIST (MANDATORY before reporting done)

       You MUST complete ALL applicable checks before reporting completion:

       â–¡ Run `bun run typecheck` - ALL errors must be resolved
       â–¡ Run `bun run lint` - ALL errors must be resolved (warnings OK)
       â–¡ Run relevant unit tests for modified areas - ALL must pass
       â–¡ For API endpoints (if API is running):
         â–¡ Run integration tests: `bun run test:integration`
         â–¡ All integration tests must pass
       â–¡ For API endpoints (Bruno verification):
         â–¡ Bruno request file exists in api-collections/{endpoint}.bru
         â–¡ Bruno file has: method, URL, example request body, expected response
         â–¡ Manually verify endpoint works (if dev server running)
       â–¡ For UI components (USE PLAYWRIGHT MCP FOR VERIFICATION):
         â–¡ Navigate to the page/route where component is rendered
         â–¡ Take a snapshot (browser_snapshot) to verify component renders
         â–¡ Check console messages (browser_console_messages) for errors
         â–¡ Click interactive elements (browser_click) to verify they work
         â–¡ Take screenshot (browser_take_screenshot) as evidence
         â–¡ Verify no accessibility violations if component is interactive
       â–¡ For database changes:
         â–¡ Migration runs without errors
         â–¡ Schema matches data-model.md

       âš ï¸ DO NOT report "done" if ANY verification fails!
       Instead, fix the issues and re-verify.

       ## [IF USER STORY GROUP (USx)] MANDATORY: Visual Feature Verification

       **This section is CRITICAL for User Story groups (US1, US2, US3, etc.)**

       After implementing your user story, you MUST visually verify the feature
       works end-to-end using Playwright MCP. This is NOT optional!

       Note: Playwright runs in HEADLESS mode (no visible browser window).
       All verification happens programmatically via MCP tools.

       ### CRITICAL: Discover Ports First
       ```bash
       # Run BEFORE any Playwright operations:
       .claude/scripts/get-dev-ports.sh
       # Use the discovered URLs for browser_navigate
       ```

       ### Steps:
       1. **Read the spec.md** to understand the acceptance criteria for your user story
       2. **Ensure dev server is running** (or start with: bun run dev)
       3. **Discover ports**: Run `.claude/scripts/get-dev-ports.sh` to get URLs
       4. **Navigate to the relevant page**: browser_navigate to discovered web URL
       4. **Take BEFORE snapshot**: browser_snapshot() to see initial state
       5. **Interact with the feature**:
          - browser_click() on buttons, links, options
          - browser_type() for text inputs
          - browser_select_option() for dropdowns
       6. **Verify expected behavior occurred**:
          - Take AFTER snapshot: browser_snapshot()
          - Check for expected UI changes
          - Verify data is displayed/updated correctly
       7. **Check for errors**: browser_console_messages() - should be clean!
       8. **Capture evidence**: browser_take_screenshot() before and after

       ### Report Format Required:
       ```
       ## Visual Verification: {User Story ID}

       | Step | Action | Expected | Actual | Status |
       |------|--------|----------|--------|--------|
       | 1 | Navigate to /generate | Page loads | Page loaded | âœ… |
       | 2 | Select Flux 2 model | Dropdown shows Flux 2 | Flux 2 selected | âœ… |
       | 3 | Generate image | JSON prompt sent | ... | âœ…/âŒ |

       Screenshots:
       - Before: [screenshot path]
       - After: [screenshot path]

       Console Errors: None / [list errors]
       ```

       âš ï¸ DO NOT report your user story as complete without visual evidence!
       The orchestrator and user need PROOF that the feature works.

       ## MANDATORY: MARK TASKS COMPLETE IN tasks.md

       After ALL tasks in your group pass verification, you MUST update tasks.md:

       1. Open the tasks.md file at: {TASKS}
       2. For EACH task you completed in this group, change:
          `- [ ] T001` â†’ `- [x] T001`
       3. Add verification marker: `- [x] T001 âœ“ (verified)`

       Example - if you completed T001, T002, T003:
       ```
       BEFORE:
       - [ ] T001 [P] [G:types] Add SHOT_DISTANCE_OPTIONS...
       - [ ] T002 [P] [G:types] Add ISO_OPTIONS...
       - [ ] T003 [P] [G:types] Add COMPOSITION_OPTIONS...

       AFTER:
       - [x] T001 [P] [G:types] Add SHOT_DISTANCE_OPTIONS... âœ“ (verified)
       - [x] T002 [P] [G:types] Add ISO_OPTIONS... âœ“ (verified)
       - [x] T003 [P] [G:types] Add COMPOSITION_OPTIONS... âœ“ (verified)
       ```

       âš ï¸ This step is CRITICAL for resume/checkpoint functionality!
       The orchestrator uses these markers to determine which waves are complete.

       Implement the COMPLETE group. Do not stop after one task.
   ```

   **MODEL SELECTION FOR SUBAGENTS:**
   ```
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘                     MODEL SELECTION RULES                            â•‘
   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
   â•‘                                                                      â•‘
   â•‘  USE OPUS FOR ALL SUBAGENTS (preferred for quality):                 â•‘
   â•‘  â€¢ subagent_type: "security"        â†’ model: "opus"                 â•‘
   â•‘  â€¢ subagent_type: "architect"       â†’ model: "opus"                 â•‘
   â•‘  â€¢ subagent_type: "frontend"        â†’ model: "opus"                 â•‘
   â•‘  â€¢ subagent_type: "backend"         â†’ model: "opus"                 â•‘
   â•‘  â€¢ subagent_type: "qa"              â†’ model: "opus"                 â•‘
   â•‘  â€¢ subagent_type: "devops"          â†’ model: "opus"                 â•‘
   â•‘  â€¢ subagent_type: "performance"     â†’ model: "opus"                 â•‘
   â•‘  â€¢ subagent_type: "scribe"          â†’ model: "opus"                 â•‘
   â•‘  â€¢ subagent_type: "general-purpose" â†’ model: "opus"                 â•‘
   â•‘                                                                      â•‘
   â•‘  RATIONALE:                                                          â•‘
   â•‘  â€¢ Opus: Latest model with best reasoning, code quality,            â•‘
   â•‘    and instruction following for all implementation tasks            â•‘
   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ```

   **Multiple groups in wave** â†’ spawn ALL subagents in parallel:
   ```
   // Wave 3 example: US1, US2, US4 can run in parallel

   Spawn 3 subagents SIMULTANEOUSLY using Task tool:

   Subagent 1 (US1):
     subagent_type: [auto-detect]
     model: [select based on subagent_type - see MODEL SELECTION above]
     prompt: "Execute Group: US1 ... [include SELF-VERIFICATION CHECKLIST]"

   Subagent 2 (US2):
     subagent_type: [auto-detect]
     model: [select based on subagent_type]
     prompt: "Execute Group: US2 ... [include SELF-VERIFICATION CHECKLIST]"

   Subagent 3 (US4):
     subagent_type: [auto-detect]
     model: [select based on subagent_type]
     prompt: "Execute Group: US4 ... [include SELF-VERIFICATION CHECKLIST]"

   Wait for ALL to complete before next wave.

   IMPORTANT: Every subagent prompt MUST include the SELF-VERIFICATION CHECKLIST.
   ```

   **C. Auto-detect subagent_type from group content:**

   ```
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘  SPECIALIST SUBAGENT TYPE DETECTION                                  â•‘
   â•‘                                                                      â•‘
   â•‘  Scan group tasks for keywords/patterns to select optimal agent.     â•‘
   â•‘  Match in order of specificity (most specific wins).                 â•‘
   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   FRONTEND SPECIALISTS (UI/UX domain)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   IF group has specialist criteria: "Design Requirements:" or "Accessibility Requirements:"
     AND mentions: components, design system, shadcn, Tailwind, styling
     â†’ subagent_type: "frontend"
       (Enhanced frontend with design system & a11y awareness)

   IF group tasks mention: accessibility, a11y, ARIA, screen reader, WCAG
     AND primarily accessibility-focused tasks
     â†’ subagent_type: "frontend"
       (Accessibility-enhanced frontend)

   IF group tasks mention: components, UI, React, .tsx, styling, responsive
     AND NOT accessibility/design-system focused
     â†’ subagent_type: "frontend"
       (Standard frontend)

   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   BACKEND SPECIALISTS (Server/Data domain)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   IF group has specialist criteria: "Database Requirements:"
     AND mentions: schema, migration, Drizzle, SQL, index, foreign key
     â†’ subagent_type: "backend"
       (Database-specialized backend)

   IF group has specialist criteria: "API Contract Requirements:"
     AND mentions: endpoint, route, Zod, Bruno, request/response
     â†’ subagent_type: "backend"
       (API-specialized backend)

   IF group has specialist criteria: "Performance Requirements:"
     AND mentions: optimization, caching, bundle, lazy load
     â†’ subagent_type: "performance"

   IF group tasks mention: API, routes, database, controllers, models
     AND NOT specialized (no specific specialist criteria)
     â†’ subagent_type: "backend"
       (Standard backend)

   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   SECURITY & QUALITY SPECIALISTS
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   IF group has specialist criteria: "Security Requirements:"
     OR mentions: auth, authentication, authorization, OAuth, JWT, vulnerability
     â†’ subagent_type: "security"

   IF group tasks mention: E2E, end-to-end, Playwright, integration test
     â†’ subagent_type: "qa"

   IF group tasks mention: tests, validation, unit test
     AND NOT E2E focused
     â†’ subagent_type: "qa"

   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   INFRASTRUCTURE SPECIALISTS
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   IF group tasks mention: deploy, Docker, k8s, Kubernetes, CI/CD, pipeline
     â†’ subagent_type: "devops"

   IF group tasks mention: logging, monitoring, observability, telemetry
     â†’ subagent_type: "backend"
       (Observability-aware backend)

   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   ARCHITECTURE & DESIGN
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   IF group tasks mention: schema design, data model, system design, architecture
     AND spans multiple services/modules
     â†’ subagent_type: "architect"

   IF group tasks mention: types, interfaces, contracts
     AND primarily type definitions
     â†’ subagent_type: "architect"

   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   DOCUMENTATION
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   IF group tasks mention: documentation, README, API docs, guide
     â†’ subagent_type: "scribe"

   IF group tasks mention: i18n, localization, translation
     â†’ subagent_type: "scribe"

   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   DEFAULT FALLBACK
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   DEFAULT: "general-purpose"
     (Use when no specific domain detected)
   ```

   **Detection Priority Summary:**
   ```
   1. Security tasks      â†’ security
   2. Performance tasks   â†’ performance
   3. E2E testing tasks   â†’ qa
   4. DevOps tasks        â†’ devops
   5. Database tasks      â†’ backend (specialized)
   6. API tasks           â†’ backend (specialized)
   7. UI/Component tasks  â†’ frontend
   8. Architecture tasks  â†’ architect
   9. Documentation tasks â†’ scribe
   10. Default            â†’ general-purpose
   ```

   **D. Wait for wave completion:**

   After spawning all subagents in a wave:
   - Wait for ALL subagents to complete
   - Collect results from each
   - Run code review (step 9) for each group
   - Run verification (step 10) for each group
   - Only proceed to next wave when current wave is fully complete

9. **Per-group code review and cleanup** (after implementation, before verification):

   ```
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘  CODE REVIEW STEP - DRY & SIMPLICITY                                 â•‘
   â•‘                                                                      â•‘
   â•‘  Purpose: Clean up implementation before tests run                   â•‘
   â•‘  Timing: After implementation subagent completes, before verificationâ•‘
   â•‘  Skip with: --skip-review flag                                       â•‘
   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ```

   **Skip conditions:**
   - If `--skip-review` flag is set: skip entirely
   - If group has 0 modified files: skip (nothing to review)

   **For each completed group, spawn a refactorer subagent:**

   ```
   Task tool:
     subagent_type: "refactorer"
     model: "opus"
     prompt: |
       ## Code Review & Cleanup: {GROUP_NAME}

       Review and clean up the implementation for DRY principles and simplicity.

       ## Files to Review
       {LIST_OF_FILES_MODIFIED_BY_IMPLEMENTATION_SUBAGENT}

       ## Review Criteria (in priority order)
       1. **DRY Violations**: Extract duplicate code into shared utilities
       2. **Unnecessary Complexity**: Simplify overly nested conditionals/loops
       3. **Dead Code**: Remove unused imports, variables, functions
       4. **Consistency**: Ensure consistent naming and patterns
       5. **Single Responsibility**: Split functions doing multiple things

       ## Mode: {IF --review-only: "REPORT ONLY" ELSE: "FIX"}

       {IF --review-only}
       **REPORT ONLY MODE**: Do NOT modify files. List issues found:
       | File | Line | Issue | Severity | Suggestion |
       |------|------|-------|----------|------------|
       {ELSE}
       **FIX MODE**: Apply fixes directly to the code.
       {ENDIF}

       ## Constraints (CRITICAL)
       - âŒ Do NOT change functionality or behavior
       - âŒ Do NOT add new features
       - âŒ Do NOT refactor unrelated code
       - âŒ Do NOT change public APIs or interfaces
       - âŒ Do NOT rename exported functions/classes (breaks imports)
       - âœ… DO extract duplicates to new private helpers
       - âœ… DO simplify complex expressions
       - âœ… DO remove dead code
       - âœ… DO improve variable/function names (internal only)

       ## Process
       1. Read each modified file
       2. Identify issues matching review criteria
       3. {IF FIX MODE: Apply minimal, focused fixes}
       4. Run `bun run typecheck` to verify no breakage
       5. Run `bun run lint` to ensure code style
       6. Report all changes made

       ## Output Format
       ```
       ## Code Review Report: {GROUP_NAME}

       ### Changes Applied (or Issues Found if report-only)
       | File | Change | Reason |
       |------|--------|--------|
       | libs/utils/api.ts | Extracted fetchWithRetry() | DRY - used in 3 places |
       | components/Form.tsx | Simplified validation logic | Reduced nesting depth |

       ### Verification
       - Typecheck: âœ… PASS
       - Lint: âœ… PASS

       ### Summary
       - Files reviewed: X
       - Changes applied: Y
       - DRY violations fixed: Z
       ```
   ```

   **Parallel review for parallel groups:**
   - If Wave 3 had US1, US2, US4 running in parallel
   - Spawn 3 refactorer subagents in parallel (one per group)
   - Each reviews only the files modified by its corresponding implementation subagent

   **Handle review results:**
   - **FIX MODE + typecheck passes**: Proceed to verification (step 10)
   - **FIX MODE + typecheck fails**: Revert changes, report issue, proceed anyway
   - **REPORT ONLY MODE**: Log issues, proceed to verification (step 10)

10. **Per-group verification** (after code review, on cleaned code):

   Before marking a group complete, verify ALL tasks in the group work:

   **A. Collect modified files from subagent report:**
   - The subagent should report all files it modified
   - Group files by area: api, web, database, types, etc.

   **B. Run verification for all modified areas:**
   ```bash
   # For TypeScript/JavaScript projects:

   # If any services/api/ files modified:
   bun test services/api --bail

   # If any apps/web/ files modified:
   bun test apps/web --bail

   # If any libs/ files modified:
   bun test libs --bail

   # Integration tests (if API endpoints modified and API is running):
   bun run test:integration

   # Always run:
   bun run typecheck
   bun run lint
   ```

   **C. Bruno API verification (MANDATORY for any API changes):**

   **WHEN TO RUN**: If ANY task in the group:
   - Created or modified files in `services/api/src/routes/`
   - Added, changed, or removed an API endpoint
   - Modified request/response schemas for an endpoint
   - Changed API behavior (even if just the handler logic)

   ```
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘                  BRUNO VERIFICATION CHECKLIST                        â•‘
   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
   â•‘                                                                      â•‘
   â•‘  For EACH API endpoint that was created or modified:                           â•‘
   â•‘                                                                      â•‘
   â•‘  1. FILE EXISTS CHECK:                                               â•‘
   â•‘     â–¡ Bruno file exists at: api-collections/{endpoint-name}.bru     â•‘
   â•‘     â–¡ Filename matches endpoint (e.g., create-lora.bru)             â•‘
   â•‘                                                                      â•‘
   â•‘  2. FILE CONTENT CHECK (each file must have):                       â•‘
   â•‘     â–¡ meta { name, type, seq }                                      â•‘
   â•‘     â–¡ method (GET, POST, PUT, DELETE, etc.)                         â•‘
   â•‘     â–¡ url with correct path and any path params                     â•‘
   â•‘     â–¡ headers (Content-Type, Authorization if needed)               â•‘
   â•‘     â–¡ body (for POST/PUT - valid JSON matching Zod schema)          â•‘
   â•‘     â–¡ script:post-response (for status code assertions)             â•‘
   â•‘                                                                      â•‘
   â•‘  3. FUNCTIONAL TEST (if dev server running):                        â•‘
   â•‘     â–¡ Run: bun run bruno:test --filter {endpoint}                   â•‘
   â•‘     â–¡ Request returns expected status code                          â•‘
   â•‘     â–¡ Response body matches expected schema                         â•‘
   â•‘                                                                      â•‘
   â•‘  FAILURE = Group verification fails, task marked âŒ                  â•‘
   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ```

   **Missing Bruno files is a VERIFICATION FAILURE.** The subagent must create them.

   **D. Handle verification results:**
   - **ALL PASS**: Mark ALL tasks in group complete `[x]`, proceed to next wave
   - **FAIL**:
     1. Capture failure in lessons-learned (step 11)
     2. Report which specific task(s) caused the failure
     3. Mark failed tasks âŒ, mark passing tasks âœ“
     4. Add group to retry queue
     5. Continue to next wave (don't block on one group failure)

   **E. Update tasks.md after group verification:**
   - Mark all verified tasks: `- [x] T001: Title âœ“ (verified)`
   - Mark failed tasks: `- [ ] T001: Title âŒ (error: {brief})`
   - Do NOT mark tasks complete before verification passes

11. **Lesson learning** (continuous throughout execution):

   Maintain `.specify/memory/lessons-learned.md` with learnings from this run.
   
   **Capture on task failure:**
```markdown
   ## {DATE} - {FEATURE_NAME}
   
   ### Failed: {TASK_ID} - {TITLE}
   **Error**: {error message}
   **Root cause**: {analysis}
   **Fix applied**: {what was done to fix}
   **Prevention**: {how to avoid in future}
```
   
   **Capture on unexpected success pattern:**
```markdown
   ### Pattern: {pattern name}
   **Context**: {when this applies}
   **What worked**: {description}
   **Reuse**: {how to apply elsewhere}
```
   
   **Capture on phase completion:**
   - Note any tasks that needed retry
   - Note any dependencies that were missing from tasks.md
   - Note any [P] markers that should have been sequential (file conflicts)
   
   **Write lessons incrementally** - don't wait until end.

12. **Update tasks.md** after each verified group:
    - Change `- [ ]` to `- [x]` for ALL verified tasks in the group
    - Add verification note: `- [x] T001: Title âœ“ (verified)`
    - For failed tasks: `- [ ] T001: Title âŒ (error: {brief})`
    - Update atomically after group verification, not after each task

13. **Progress reporting**:
```
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    WAVE 1: Setup
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â— Group: setup (3 tasks) â†’ 1 subagent
      T001, T002, T003 â†’ implemented â†’ reviewed (2 fixes) â†’ verified âœ…
    â— Wave 1 Complete

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    WAVE 2: Foundation
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â— Group: foundation (6 tasks) â†’ 1 subagent
      T004-T009 â†’ implemented â†’ reviewed (0 fixes) â†’ verified âœ…
    â— Wave 2 Complete

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    WAVE 3: User Stories (PARALLEL)
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â— Group: US1 (6 tasks) â†’ subagent 1 â†’ reviewed (1 fix) âœ…
    â— Group: US2 (12 tasks) â†’ subagent 2 â†’ reviewed (3 fixes) âœ…
    â— Group: US4 (4 tasks) â†’ subagent 3 â†’ reviewed (0 fixes) âœ…
    â— Wave 3 Complete (3 groups in parallel)

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    WAVE 4: Dependent Stories
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    â— Group: US3 (4 tasks) â†’ 1 subagent
      T028-T031 â†’ implemented â†’ reviewed â†’ FAILED âŒ (T030 type error)
    â— Wave 4 Complete with errors

    âš ï¸ Failed groups: US3 (retry with --retry US3)
```

14. **End-of-run summary**:
```
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        EXECUTION COMPLETE
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    EXECUTION MODEL:
      Total tasks: 39
      Execution groups: 8
      Subagents spawned: 16 (8 impl + 8 review)

    RESULTS:
      Groups passed: 7/8 âœ…
      Groups failed: 1/8 âŒ
      Tasks passed: 35/39
      Tasks failed: 4/39

    CODE REVIEW:
      Groups reviewed: 8
      Total fixes applied: 6
      DRY violations fixed: 4
      Complexity reductions: 2
      Files cleaned: 12

    WAVES:
      âœ… Wave 1: Setup (1 group, 3 tasks) - 2 review fixes
      âœ… Wave 2: Foundation (1 group, 6 tasks) - 0 review fixes
      âœ… Wave 3: US1, US2, US4 (3 groups parallel, 22 tasks) - 4 review fixes
      âŒ Wave 4: US3 (1 group, 4 tasks) - FAILED
      âœ… Wave 5: Polish (1 group, 4 tasks) - 0 review fixes

    FAILED GROUPS:
      US3: T030 type error in GenerationPanel.tsx
           â†’ Retry: /speckit.run --retry US3

    LESSONS CAPTURED: 2 entries
      â†’ .specify/memory/lessons-learned.md updated

    VERIFICATION:
      Tests run: 47
      Tests passed: 45
      Typecheck: âœ…
      Lint: âœ…

    NEXT STEPS:
      1. Fix failed group: /speckit.run --retry US3
      2. Or skip and test: /sc:test --comprehensive
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

15. **Final lesson learning pass**:

    After all phases, append summary to lessons-learned.md:
```markdown
    ### Run Summary: {DATE}
    **Feature**: {FEATURE_NAME}
    **Success rate**: {X}/{Y} tasks
    **Key learnings**:
    - {learning 1}
    - {learning 2}
    **Recommendations for next run**:
    - {recommendation}
```

16. **APPROVAL GATE** (MANDATORY - DO NOT SKIP):

    After presenting the end-of-run summary, present this approval request and **WAIT for user response**:

    ```
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      APPROVAL REQUIRED: Implementation Review
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Feature: {FEATURE_NAME}
    Implementation: {FEATURE_DIR}

    Execution Summary:
      | Metric | Result |
      |--------|--------|
      | Tasks Completed | {X}/{Y} |
      | Groups Passed | {X}/{Y} |
      | Waves Completed | {X}/{Y} |
      | Tests Passing | {X}/{Y} |
      | Typecheck | {PASS/FAIL} |
      | Lint | {PASS/FAIL} |
      | Bruno Files | {X created/updated} |

    Failed Items (if any):
      - {Group/Task}: {error summary}

    Files Modified:
      - {count} files across {areas}

    Lessons Captured: {count} entries

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      YOUR ACTION REQUIRED
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    Review the implementation and then respond with ONE of:
      [A] APPROVE  - Proceed to /sc:test --comprehensive
      [B] RETRY    - Re-run failed groups (specify which)
      [C] FIX      - Manual fixes needed before testing
      [D] PAUSE    - "I'll review and get back to you"

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ```

    **CRITICAL**: Do NOT suggest running the next command or proceed automatically.
    Wait for explicit user approval before suggesting next steps.

    **On user approval**: Remind them to run `/sc:test --comprehensive` with `FEATURE_DIR: {path}`

## Key Rules

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     EXECUTION MODEL RULES                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                      â•‘
â•‘  RULE 1: ONE SUBAGENT PER GROUP                                     â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘  â€¢ [USx] tasks â†’ ALL go to ONE subagent                             â•‘
â•‘  â€¢ [G:name] tasks â†’ ALL go to ONE subagent                          â•‘
â•‘  â€¢ Unlabeled tasks in phase â†’ ALL go to ONE subagent                â•‘
â•‘  â€¢ NEVER spawn one subagent per task                                â•‘
â•‘                                                                      â•‘
â•‘  RULE 2: [P] IS DOCUMENTATION ONLY                                  â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘  â€¢ [P] does NOT spawn separate subagents                            â•‘
â•‘  â€¢ [P] tells the subagent "this task has no internal dependencies"  â•‘
â•‘  â€¢ [P] helps the subagent optimize its execution order              â•‘
â•‘                                                                      â•‘
â•‘  RULE 3: PARALLELISM IS AT THE GROUP LEVEL                          â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘  â€¢ Groups with satisfied dependencies run in PARALLEL               â•‘
â•‘  â€¢ US1, US2, US4 can run simultaneously (3 subagents)               â•‘
â•‘  â€¢ This is where the real speedup comes from                        â•‘
â•‘                                                                      â•‘
â•‘  RULE 4: VERIFY GROUPS, NOT TASKS                                   â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘  â€¢ Run verification AFTER the group subagent completes              â•‘
â•‘  â€¢ Mark ALL tasks in group as verified if tests pass                â•‘
â•‘  â€¢ Don't verify task-by-task                                        â•‘
â•‘                                                                      â•‘
â•‘  RULE 5: CODE REVIEW BEFORE VERIFICATION                            â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘  â€¢ Refactorer subagent reviews AFTER implementation completes       â•‘
â•‘  â€¢ Reviews happen BEFORE verification (tests run on cleaned code)   â•‘
â•‘  â€¢ Focus: DRY violations, complexity, dead code, consistency        â•‘
â•‘  â€¢ Skip with --skip-review flag (not recommended)                   â•‘
â•‘  â€¢ Report-only mode with --review-only flag (no fixes applied)      â•‘
â•‘                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Additional Rules:**
- **Learn from failures**: Every failure gets captured in lessons-learned.md
- **SuperClaude auto-activation**: Don't manually assign personas - auto-detect from task content
- **Atomic updates**: Update tasks.md after each GROUP verification, not task-by-task
- **Wave boundaries**: Complete ALL groups in a wave before proceeding to next wave
- **Dependency respect**: Never start a group until its dependencies are satisfied
- **Code review flow**: Implementation â†’ Review â†’ Verification (tests always run on cleaned code)
- **Review constraints**: Refactorer must NOT change functionality, only clean up DRY/complexity issues

## Specialist-Enhanced Tasks

Tasks from `speckit.tasks` may include **specialist requirements** added during the task generation phase. These requirements are embedded in task criteria blocks:

```markdown
**Example task with specialist enhancements:**

- [ ] T022 [P] [US2] Create MentionAutocomplete component

  **Design Requirements:** (from ui-designer specialist)
  - [ ] Follow design system tokens (colors, spacing, typography)
  - [ ] Responsive: mobile (320px), tablet (768px), desktop (1024px+)
  - [ ] Dark mode support if design system includes it

  **Accessibility Requirements:** (from accessibility-specialist)
  - [ ] Semantic HTML elements (button, nav, main, etc.)
  - [ ] ARIA labels for interactive elements
  - [ ] Keyboard navigation (Tab, Enter, Escape, Arrow keys)
  - [ ] Focus visible states (:focus-visible)

  **UX Flow Requirements:** (from ux-flow-specialist)
  - [ ] Loading state with skeleton/spinner
  - [ ] Error state with recovery action
  - [ ] Empty state with call-to-action
```

**When executing specialist-enhanced tasks:**
1. Include ALL specialist requirements in the subagent prompt
2. The subagent MUST implement all checklist items
3. Verification should check specialist requirements are met
4. Missing specialist requirements = verification failure

## MCP Server Integration

Subagents should leverage MCP servers based on their domain:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MCP SERVER RECOMMENDATIONS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  FRONTEND SUBAGENTS:                                                    â”‚
â”‚  â€¢ magic         â†’ UI component generation, design system patterns      â”‚
â”‚  â€¢ context7      â†’ React, shadcn, Tailwind documentation               â”‚
â”‚  â€¢ playwright    â†’ MANDATORY for visual verification!                   â”‚
â”‚                    - browser_navigate to component page                 â”‚
â”‚                    - browser_snapshot to verify render                  â”‚
â”‚                    - browser_click to test interactions                 â”‚
â”‚                    - browser_take_screenshot as evidence                â”‚
â”‚                    - browser_console_messages for error checking        â”‚
â”‚                                                                         â”‚
â”‚  BACKEND SUBAGENTS:                                                     â”‚
â”‚  â€¢ context7      â†’ Hono, Drizzle, Bun, Zod documentation               â”‚
â”‚  â€¢ sequential    â†’ Complex API design, database optimization            â”‚
â”‚                                                                         â”‚
â”‚  SECURITY SUBAGENTS:                                                    â”‚
â”‚  â€¢ sequential    â†’ Threat modeling, security analysis                   â”‚
â”‚  â€¢ context7      â†’ OWASP patterns, security best practices              â”‚
â”‚                                                                         â”‚
â”‚  PERFORMANCE SUBAGENTS:                                                 â”‚
â”‚  â€¢ playwright    â†’ Lighthouse, Core Web Vitals measurement              â”‚
â”‚  â€¢ sequential    â†’ Bottleneck analysis, optimization planning           â”‚
â”‚                                                                         â”‚
â”‚  QA SUBAGENTS:                                                          â”‚
â”‚  â€¢ playwright    â†’ E2E test execution, cross-browser testing            â”‚
â”‚  â€¢ sequential    â†’ Test scenario planning, edge case analysis           â”‚
â”‚                                                                         â”‚
â”‚  DEVOPS SUBAGENTS:                                                      â”‚
â”‚  â€¢ sequential    â†’ Deployment planning, infrastructure analysis         â”‚
â”‚  â€¢ context7      â†’ Docker, k8s, CI/CD patterns                          â”‚
â”‚                                                                         â”‚
â”‚  ARCHITECT SUBAGENTS:                                                   â”‚
â”‚  â€¢ sequential    â†’ System design, architectural analysis                â”‚
â”‚  â€¢ context7      â†’ Design patterns, best practices                      â”‚
â”‚  â€¢ serena        â†’ Codebase semantic analysis, refactoring              â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Include MCP guidance in subagent prompts when relevant:**

For **User Story subagents (US1, US2, etc.)**, include:
```
## MCP Servers Available
- Use context7 for library documentation lookup
- Use magic for UI component generation (if frontend work)
- Use playwright for MANDATORY visual verification

## MANDATORY: Visual Feature Verification with Playwright
Your user story must be VISUALLY VERIFIED before completion:

âš ï¸ DISCOVER PORTS FIRST (never hardcode!):
```bash
.claude/scripts/get-dev-ports.sh
# Returns: web=XXXX, api=YYYY with URLs
```

1. Read spec.md to understand acceptance criteria
2. Ensure dev server is running (bun run dev)
3. browser_navigate to http://localhost:{web_port}/... (the page affected by your user story)
4. browser_snapshot BEFORE interacting with your feature
5. Interact with your feature (browser_click, browser_type, etc.)
6. browser_snapshot AFTER to verify the expected change
7. browser_console_messages to confirm no errors
8. browser_take_screenshot as evidence for both states

REPORT FORMAT:
| Step | Action | Expected | Actual | Status |
|------|--------|----------|--------|--------|

DO NOT report done without visual evidence that your user story works!
```

For **frontend** subagents, include:
```
## MCP Servers Available
- Use context7 for React/shadcn/Tailwind documentation
- Use magic for UI component generation and design patterns

## MANDATORY: Visual Verification with Playwright
After implementing UI components, you MUST verify they work:

âš ï¸ DISCOVER PORTS FIRST (never hardcode!):
```bash
.claude/scripts/get-dev-ports.sh
# Returns: web=XXXX, api=YYYY with URLs
```

1. Ensure dev server is running (or start with: bun run dev)
2. browser_navigate to http://localhost:{web_port}/... (the page where your component lives)
3. browser_snapshot to verify it renders correctly
4. browser_console_messages to check for errors
5. browser_click on interactive elements to test functionality
6. browser_take_screenshot to capture evidence of working UI

DO NOT report done until you have visually verified the component works!
```

For **backend/other** subagents, include:
```
## MCP Servers Available
- Use context7 for library documentation lookup
- Use sequential for complex multi-step analysis
```

## Important: Subagent Delegation

**CRITICAL**: This command orchestrates, it does NOT implement directly.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ORCHESTRATOR RESPONSIBILITIES                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  DO:                                                            â”‚
â”‚  âœ“ Parse tasks.md and extract groups                           â”‚
â”‚  âœ“ Build execution wave map from dependencies                  â”‚
â”‚  âœ“ Spawn ONE subagent per GROUP using Task tool                â”‚
â”‚  âœ“ Spawn multiple subagents in PARALLEL for same-wave groups   â”‚
â”‚  âœ“ Wait for subagents to complete                              â”‚
â”‚  âœ“ Run verification after each group completes                 â”‚
â”‚  âœ“ Update tasks.md with results                                â”‚
â”‚  âœ“ Report progress after each wave                             â”‚
â”‚                                                                 â”‚
â”‚  DO NOT:                                                        â”‚
â”‚  âœ— Implement code directly                                     â”‚
â”‚  âœ— Spawn one subagent per task (WRONG!)                        â”‚
â”‚  âœ— Use [P] marker to spawn separate subagents (WRONG!)         â”‚
â”‚  âœ— Skip verification                                           â”‚
â”‚  âœ— Modify tasks.md before verification                         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Subagent spawning:**
- Use the **Task tool** with appropriate `subagent_type` (auto-detect from group content)
- Pass ALL tasks in the group to the subagent in a single prompt
- For parallel groups in the same wave: spawn ALL subagents simultaneously in one tool call batch

**Example - Wave 3 with 3 parallel groups:**
```
// CORRECT: Spawn 3 subagents in ONE message with 3 Task tool calls
Task tool call 1: { subagent_type: "backend", prompt: "Execute Group: US1..." }
Task tool call 2: { subagent_type: "frontend", prompt: "Execute Group: US2..." }
Task tool call 3: { subagent_type: "backend", prompt: "Execute Group: US4..." }

// WRONG: Spawning 12 subagents for US2's 12 tasks
```